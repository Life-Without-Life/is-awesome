{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZmxe8WEyOE0"
      },
      "source": [
        "https://www.kaggle.com/code/jimbothehut/content-based-manga-recommender-system/notebook\n",
        "\n",
        "https://github.com/kk7nc/Text_Classification#rocchio-classification\n",
        "\n",
        "https://queryunderstanding.com/query-expansion-2d68d47cf9c8\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHzt1OlYPLKF",
        "outputId": "205de69b-0972-44fe-b871-02cdf27c4ee6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,  CountVectorizer\n",
        "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import math\n",
        "import string\n",
        "from itertools import groupby\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IR_CJ9KPeZm",
        "outputId": "a7ad8939-1a11-4ed5-d82e-8296fe96b48d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8UYCY9LbJw9"
      },
      "outputs": [],
      "source": [
        "def remove_stop_words(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    text = text.translate(translator)\n",
        "    return text\n",
        "\n",
        "def lowercase(text):\n",
        "  return text.lower()\n",
        "\n",
        "def preprocess(text):\n",
        "  text = lowercase(text)\n",
        "  text = remove_punctuation(text)\n",
        "  text = remove_stop_words(text)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0CuyVYOPiQc"
      },
      "outputs": [],
      "source": [
        "keywords = open(\"keywords.txt\").readlines()\n",
        "keywords = [x.strip() for x in keywords]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApZaDYHYQ-pI"
      },
      "outputs": [],
      "source": [
        "documents = open(\"documents.txt\", encoding='utf-8-sig').read().split('\\n\\n')\n",
        "documents = [x.replace('\\n', ' ').replace('...', '').replace('ï¿½', '').replace('.  ', '.') for x in documents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qsaUrWQSj9L"
      },
      "outputs": [],
      "source": [
        "process_docs = [preprocess(x).lower() for x in documents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def wordcount(doc):\n",
        "  word_count = defaultdict(int)\n",
        "  for sentence in doc:\n",
        "    for word in sentence.split():\n",
        "      word_count[word] += 1\n",
        "  word_count = dict(sorted(word_count.items(), key = lambda x : x[1], reverse = True))\n",
        "  return word_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def zipf_plot(doc):\n",
        "  word_count = wordcount(doc)\n",
        "  plt.figure(figsize = (50, 10))\n",
        "  plt.tight_layout()\n",
        "  plt.xlabel('Words', fontsize = 27)\n",
        "  plt.ylabel('Frequency', fontsize = 27)\n",
        "  plt.xticks(rotation=90, fontsize = 5)\n",
        "  plt.bar(word_count.keys(), word_count.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "zipf_plot(process_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def heaps_plot(doc):\n",
        "    frequency = []\n",
        "    for i in doc:\n",
        "        f = len(i)\n",
        "        l = []\n",
        "        c = 0\n",
        "        for j in i:\n",
        "          if j not in l:\n",
        "            c+=1\n",
        "            l.append(j)\n",
        "        frequency.append([f, c])\n",
        "    frequency.sort(reverse = True)\n",
        "    plt.plot(frequency[:][0], frequency[:][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOYwefAWg946",
        "outputId": "bd7ae9e3-22d7-4011-dabe-d4f29e914de1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(88, 120)\n"
          ]
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer(vocabulary=keywords)\n",
        "X = vectorizer.fit_transform(process_docs)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGCXTYs3dFmy"
      },
      "outputs": [],
      "source": [
        "def cosine_sim(query, X):\n",
        "    q_tfidf = vectorizer.fit_transform([query])\n",
        "    results = cosine_similarity(X,q_tfidf).reshape((-1,))\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlgoqfP2iZdq"
      },
      "outputs": [],
      "source": [
        "def query_search(results):\n",
        "    print(\"Top 10 Documents matched: \")\n",
        "    j = 0\n",
        "    res = []\n",
        "    for i in results.argsort()[-10:][::-1]:\n",
        "        j += 1\n",
        "        print(\"Document {:02d}: \".format(j), documents[i])\n",
        "        res.append(documents[i])\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4IXMmPnB1hi"
      },
      "outputs": [],
      "source": [
        "def get_relevance(results):\n",
        "    res_bool = []\n",
        "    for x in range(len(results)):\n",
        "        ch = input(f\"Type R or N for document {x+1} being relevant and non-relevant respectively: \")\n",
        "        if ch == 'R' or ch == 'r':\n",
        "            res_bool.append(True)\n",
        "        else:\n",
        "            res_bool.append(False)\n",
        "    return res_bool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5dhV3wIQOsy"
      },
      "outputs": [],
      "source": [
        "def get_vectors(docs):\n",
        "    vec = []\n",
        "    for x in docs:\n",
        "        i = documents.index(x)\n",
        "        vec.append(X[i])\n",
        "    return vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OE_TIEK8Jsja"
      },
      "outputs": [],
      "source": [
        "def rocchio_rel(query, vectors, rel_vec, alpha=1, beta=0.8, gamma=0.1):\n",
        "    rels_ = [vectors[i] for i in range(len(vectors)) if rel_vec[i] == True]\n",
        "    non_rels = [vectors[i] for i in range(len(vectors)) if rel_vec[i] == False]\n",
        "    C1 = sum(rels_) / len(rels_)\n",
        "    C2 = sum(non_rels) / len(non_rels)\n",
        "    q = vectorizer.fit_transform([query])\n",
        "    q1 = alpha * q + beta * C1 - gamma * C2\n",
        "    results = cosine_similarity(X,q1).reshape((-1,))\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03DhN_4eHzao",
        "outputId": "21cfd1e3-18d0-4996-ec12-f7ad1fcfc8b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 Documents matched: \n",
            "Document 01:  15-681 and 15-781 Machine Learning Machine Learning, 15:681 and 15:781, Fall 1998.This course covers the theory and practice of machine learning from a variety of perspectives.\n",
            "Document 02:  C4.5: Programs for Machine Learning By Author. C4.5: Programs for Machine Learning J. Ross Quinlan, The Morgan Kaufmann Series in Machine  \n",
            "Document 03:  Machine Learning Machine Learning, THE  Machine learning refers to a system capable of the autonomous acquisition and integration of knowledge. This  \n",
            "Document 04:  Machine Learning 6.858/18.428: Machine Learning. Available Lecture Notes.Defining models for machine learning. Learning conjunctions in the mistake-bounded model.\n",
            "Document 05:  Machine Learning 6.858/18.428: Machine Learning.This course deals with the following topics: Formal models of machine learning; Learning concepts from examples;  \n",
            "Document 06:  Machine Learning FAQ Machine Learning FAQ. Machine Learning Frequently Asked Questions. Click Here to access our page. You are using a Browser that does not support Frames. Description: Questions and answers about Machine Learning. Anyone can post his/her own questions and answers.\n",
            "Document 07:  BYU Neural Networks and Machine Learning Lab BYU Neural Networks and Machine Learning Laboratory. Lab Director - Tony Martinez.Links to other Neural Network and Machine Learning resources.\n",
            "Document 08:  Machine Learning Machine Learning. Machine Learning Home Page (Editor) Machine Learning Home Page (Publisher) Machine Learning Online by Kluwer Academic Publishers:  \n",
            "Document 09:  Machine Learning and Neural Networks Group - Universities of   Machine Learning and Neural Networks group. People. Faculty. Ph.D Students. Paolo Frasconi., Machine learning for the web. , Neural networks for QSPR/QSAR. ,  \n",
            "Document 10:  Machine Learning Machine Learning. Related Sites. Machine Learning Resources courtesy of David Aha A Machine Learning Tutorial a good overview of the  \n"
          ]
        }
      ],
      "source": [
        "query = 'neural machine learning'\n",
        "query_docs = query_search(cosine_sim(query, X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu2JPytvWxlp",
        "outputId": "9da52937-c17f-4577-d03f-fb784a01080a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type R or N for document 1 being relevant and non-relevant respectively: R\n",
            "Type R or N for document 2 being relevant and non-relevant respectively: N\n",
            "Type R or N for document 3 being relevant and non-relevant respectively: R\n",
            "Type R or N for document 4 being relevant and non-relevant respectively: R\n",
            "Type R or N for document 5 being relevant and non-relevant respectively: R\n",
            "Type R or N for document 6 being relevant and non-relevant respectively: N\n",
            "Type R or N for document 7 being relevant and non-relevant respectively: N\n",
            "Type R or N for document 8 being relevant and non-relevant respectively: R\n",
            "Type R or N for document 9 being relevant and non-relevant respectively: R\n",
            "Type R or N for document 10 being relevant and non-relevant respectively: R\n",
            "Top 10 Documents matched: \n",
            "Document 01:  15-681 and 15-781 Machine Learning Machine Learning, 15:681 and 15:781, Fall 1998.This course covers the theory and practice of machine learning from a variety of perspectives.\n",
            "Document 02:  C4.5: Programs for Machine Learning By Author. C4.5: Programs for Machine Learning J. Ross Quinlan, The Morgan Kaufmann Series in Machine  \n",
            "Document 03:  Machine Learning 6.858/18.428: Machine Learning. Available Lecture Notes.Defining models for machine learning. Learning conjunctions in the mistake-bounded model.\n",
            "Document 04:  Machine Learning Machine Learning, THE  Machine learning refers to a system capable of the autonomous acquisition and integration of knowledge. This  \n",
            "Document 05:  Machine Learning 6.858/18.428: Machine Learning.This course deals with the following topics: Formal models of machine learning; Learning concepts from examples;  \n",
            "Document 06:  Machine Learning FAQ Machine Learning FAQ. Machine Learning Frequently Asked Questions. Click Here to access our page. You are using a Browser that does not support Frames. Description: Questions and answers about Machine Learning. Anyone can post his/her own questions and answers.\n",
            "Document 07:  Machine Learning Machine Learning. Machine Learning Home Page (Editor) Machine Learning Home Page (Publisher) Machine Learning Online by Kluwer Academic Publishers:  \n",
            "Document 08:  Machine Learning Machine Learning. Related Sites. Machine Learning Resources courtesy of David Aha A Machine Learning Tutorial a good overview of the  \n",
            "Document 09:  Machine Learning CiteSeer; NEC Research Institute; Steve    machine learning researchers that the Bayesian 56 Multiagent Systems: A Survey from a Machine Learning Perspective - Stone, Veloso (1997) (Correct) Distributed  \n",
            "Document 10:  UCI Machine Learning Group Machine learning investigates the mechanisms by which knowledge is acquired through experience.UCI Machine Learning Information.\n"
          ]
        }
      ],
      "source": [
        "relevance = get_relevance(query_docs)\n",
        "tfidf_vectors = get_vectors(query_docs)\n",
        "rocchio_results = rocchio_rel(query, tfidf_vectors, relevance)\n",
        "q_docs = query_search(rocchio_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XnrlREXQk--"
      },
      "outputs": [],
      "source": [
        "countvect = CountVectorizer(min_df=5, max_df=0.9, stop_words='english', lowercase=True, token_pattern='[a-zA-Z\\-][a-zA-Z\\-]{2,}')\n",
        "count_docs = countvect.fit_transform(process_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eyda-xuQRnZ_",
        "outputId": "48f79668-6d13-4e9d-cecb-cf80588c4bea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n"
          ]
        }
      ],
      "source": [
        "NUM_TOPICS = 10\n",
        "lda = LatentDirichletAllocation(n_components=NUM_TOPICS, max_iter=10, learning_method='online',verbose=True)\n",
        "data_lda = lda.fit_transform(count_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3hGvdtDVKwZ"
      },
      "outputs": [],
      "source": [
        "def selected_topics(model, vectorizer, top_n=10):\n",
        "    for idx, topic in enumerate(model.components_):\n",
        "        print(\"Topic %d:\" % (idx))\n",
        "        print([(vectorizer.get_feature_names_out()[i], topic[i])\n",
        "                        for i in topic.argsort()[:-top_n - 1:-1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaH3ZnL1VNDZ",
        "outputId": "079b256d-7389-4761-e233-584b74f3b5cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LDA Model: \n",
            "Topic 0:\n",
            "[('group', 8.985601734978186), ('research', 6.522558818474625), ('description', 6.250855557102563), ('computer', 5.042182784458683), ('algorithms', 4.026352816259424), ('classification', 2.616914148683244), ('home', 2.1959980032577393), ('science', 1.9489734393136977), ('page', 1.4417100403100485), ('information', 1.2995399185728993)]\n",
            "Topic 1:\n",
            "[('research', 17.83141639820532), ('group', 11.88433318210909), ('systems', 5.041024491991795), ('description', 4.84930073346815), ('university', 3.46782086757878), ('new', 2.5905503175603095), ('information', 2.057256239727811), ('overview', 1.8964796849256063), ('pages', 1.8382749340652973), ('computer', 1.7560203016429135)]\n",
            "Topic 2:\n",
            "[('page', 12.230608657719868), ('home', 10.274729230834941), ('pages', 4.311083738882294), ('description', 4.286673016904455), ('artificial', 3.517065184524415), ('intelligence', 3.511844774029209), ('new', 1.9013320747932734), ('people', 1.535343806661428), ('web', 1.2416971291645875), ('applications', 1.106654242549619)]\n",
            "Topic 3:\n",
            "[('conference', 6.763393918887876), ('international', 4.387425111553614), ('description', 2.548733773709178), ('web', 1.9106629670912714), ('resources', 1.8764001690805523), ('home', 1.8379880434859732), ('icml', 1.1544894071361347), ('applications', 1.096996446682423), ('online', 1.0880186691943137), ('page', 1.0834964131963856)]\n",
            "Topic 4:\n",
            "[('information', 17.89925232212304), ('resources', 8.266026935573137), ('neural', 6.036724861577491), ('networks', 4.153822357695625), ('description', 3.765376431405463), ('online', 3.4906049329778317), ('overview', 2.829741368581692), ('web', 2.4705242167462043), ('research', 2.428636041213829), ('algorithms', 2.085072956008693)]\n",
            "Topic 5:\n",
            "[('applications', 3.8029158190274144), ('science', 3.0117198530768534), ('international', 2.686453408818023), ('computer', 2.095176201982885), ('home', 1.2127943779608663), ('knowledge', 1.1784643457502058), ('artificial', 1.1113385855097238), ('intelligence', 1.050383471415569), ('pages', 1.0414744601809676), ('group', 0.529930687455689)]\n",
            "Topic 6:\n",
            "[('systems', 1.1114447373808622), ('journal', 1.0895417671027956), ('international', 0.3483234316757627), ('home', 0.3258736945601494), ('conference', 0.32031515742030464), ('networks', 0.3098411084729726), ('knowledge', 0.29916413281528675), ('overview', 0.2915797286210921), ('information', 0.28955667900167575), ('web', 0.2878615096388745)]\n",
            "Topic 7:\n",
            "[('neural', 6.200866529554133), ('networks', 4.246643248810044), ('university', 3.5700576342861567), ('group', 1.9106068173119248), ('classification', 1.8023903394220002), ('description', 1.3284635292363747), ('students', 1.0494098293446417), ('science', 1.042925980113956), ('people', 1.0380352838125129), ('web', 1.0291642602011994)]\n",
            "Topic 8:\n",
            "[('data', 13.934440347156848), ('icml', 12.217071006102747), ('mining', 11.509495398383963), ('description', 6.91170417539849), ('international', 6.394506602776229), ('conference', 5.595226352244362), ('knowledge', 5.063051133551839), ('discovery', 4.273471310837611), ('research', 3.101397579250085), ('home', 3.085614663843914)]\n",
            "Topic 9:\n",
            "[('journal', 1.0960176333880214), ('new', 1.0854991724534973), ('page', 0.4139925759684082), ('home', 0.37332532164756), ('pages', 0.36022207784396904), ('online', 0.34102520169241496), ('conference', 0.3334074290947874), ('information', 0.3163871456784697), ('students', 0.30793151153104265), ('university', 0.29954151353905883)]\n"
          ]
        }
      ],
      "source": [
        "print('LDA Model: ')\n",
        "selected_topics(lda, countvect)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
